{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 16:44:05.516176: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-26 16:44:05.516198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-26 16:44:05.516974: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-26 16:44:05.520905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-26 16:44:06.074720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 16:44:06.785111: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.786403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.806806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.808074: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.808171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.809412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.810517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.810644: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.810731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.869931: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.870053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.870144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 16:44:06.870213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# create config to use both gpus on wickerman machine:\n",
    "# 1. Nvidia A40 (25GB memory allocation)\n",
    "# 2. Nvidia RTX 3060 (11GB memory allocation)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# tf.config.set_visible_devices(gpus[0], 'GPU') # use Use Nvidia A40 only\n",
    "\n",
    "# log_dev_conf_a40 = tf.config.LogicalDeviceConfiguration(\n",
    "#     memory_limit=25*1024 # 25 GB allocation for a40 GPU\n",
    "# )\n",
    "\n",
    "# tf.config.set_logical_device_configuration(\n",
    "#     gpus[0], # select GPU_0, i.e., Nvidia A40\n",
    "#     [log_dev_conf_a40] # apply 25GB config\n",
    "# )\n",
    "\n",
    "tf.config.set_visible_devices(gpus[1], 'GPU') # use RTX3060 only\n",
    "\n",
    "log_dev_conf_rtx3060 = tf.config.LogicalDeviceConfiguration(\n",
    "    memory_limit=12*1024 # 11 GB allocation for rtx3060 GPU\n",
    ")\n",
    "\n",
    "tf.config.set_logical_device_configuration(\n",
    "    gpus[1], # select GPU_1, i.e., Nvidia rtx3060\n",
    "    [log_dev_conf_rtx3060] # apply 11GB config\n",
    ")\n",
    "\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from pqdm.threads import pqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 18:39:21.020980: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
    "\n",
    "# model_id = \"google-t5/t5-base\"\n",
    "model_id = 'google/flan-t5-base'\n",
    "\n",
    "# with strategy.scope():\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"models/v2\")\n",
    "# model = TFT5ForConditionalGeneration.from_pretrained(\"models/v4\")\n",
    "# model = TFT5ForConditionalGeneration.from_pretrained(\"ckpts/v4/ckpt-0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path) as input_file:\n",
    "        lines = list(map(json.loads, input_file))\n",
    "\n",
    "    return lines\n",
    "\n",
    "def load_data(root_path):\n",
    "    files = os.listdir(root_path)\n",
    "    dataset= {}\n",
    "\n",
    "    for filename in files:\n",
    "        filepath = root_path + f'/{filename}'\n",
    "\n",
    "        dataset[filename] = load_jsonl(filepath)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data('data/L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "models = ['llama3.1', 'gemma2:2b', 'gemma2']\n",
    "\n",
    "test_from = 'attrebute_val'\n",
    "train_from = 'attrebute_train'\n",
    "target_from = 'attrebute_test'\n",
    "\n",
    "train_inputs = train_from + '.data'\n",
    "train_labels = train_from + '.solution'\n",
    "\n",
    "test_inputs = test_from + '.data'\n",
    "test_labels = test_from + '.solution'\n",
    "\n",
    "target_inputs = target_from + '.data'\n",
    "\n",
    "test_inputs = dataset[test_inputs]\n",
    "test_labels = dataset[test_labels]\n",
    "train_inputs = dataset[train_inputs]\n",
    "train_labels = dataset[train_labels]\n",
    "target_inputs = dataset[target_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 256, 30522)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN=250\n",
    "prompt = {\n",
    "    \"label\": \"The product belongs to these categories:\\nBrand: {details_Brand}\\nLevel 0: {L0_category}\\nLevel 1: {L1_category}\\nLevel 2: {L2_category}\\nLevel 3: {L3_category}\\nLevel 4: {L4_category}\",\n",
    "    \"input\": \"Categories the product into 5 levels of categories and identify the brand:\\nTitle: {title}\\nStore:{store}\\nManufacturer:{details_Manufacturer}\"\n",
    "}\n",
    "\n",
    "def make_prompt(data):\n",
    "    if 'title' in data:\n",
    "        input_type = 'input'\n",
    "    else:\n",
    "        input_type = 'label'\n",
    "\n",
    "    prompt = {\n",
    "        \"label\": \"The product belongs to these categories:\\nBrand: {details_Brand}\\nLevel 0: {L0_category}\\nLevel 1: {L1_category}\\nLevel 2: {L2_category}\\nLevel 3: {L3_category}\\nLevel 4: {L4_category}\",\n",
    "        \"input\": \"Categorise the product into 5 levels of categories and identify the brand:\\nTitle: {title}\\nStore:{store}\\nManufacturer:{details_Manufacturer}\"\n",
    "    }\n",
    "\n",
    "    return prompt[input_type].format(**data)\n",
    "\n",
    "def batch_make_prompt(data):\n",
    "    return [make_prompt(item) for item in data]\n",
    "# def tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_prompts = pqdm(train_inputs, make_prompt, n_jobs=5)\n",
    "train_label_prompts = pqdm(train_labels, make_prompt, n_jobs=5)\n",
    "test_input_prompts = pqdm(test_inputs, make_prompt, n_jobs=5)\n",
    "test_label_prompts = pqdm(test_labels, make_prompt, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(inputs, labels, return_output=False):\n",
    "    inputs = [item.decode() for item in inputs]\n",
    "    labels = [item.decode() for item in labels]\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "    target_encoding = tokenizer(\n",
    "        labels,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    labels = target_encoding.input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    preds = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    if not return_output:\n",
    "        return preds.loss\n",
    "    \n",
    "    return preds, preds.loss\n",
    "\n",
    "def predict(inputs):\n",
    "    \n",
    "\n",
    "    encoding = tokenizer.batch_encode_plus(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "    outputs = model.generate(input_ids, max_new_tokens=SEQ_LEN)\n",
    "\n",
    "    return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
