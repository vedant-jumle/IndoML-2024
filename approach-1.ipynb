{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 23:16:04.557700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-02 23:16:04.557721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-02 23:16:04.558585: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-02 23:16:04.562685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 23:16:05.104875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 23:16:05.736321: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.737636: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.759943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.761215: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.761314: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.762620: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.763582: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.764825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.766008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.872302: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.873667: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.874938: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 23:16:05.876123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46080 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# create config to use both gpus on wickerman machine:\n",
    "# 1. Nvidia A40 (25GB memory allocation)\n",
    "# 2. Nvidia RTX 3060 (11GB memory allocation)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU') # use Use Nvidia A40 only\n",
    "\n",
    "log_dev_conf_a40 = tf.config.LogicalDeviceConfiguration(\n",
    "    memory_limit=45*1024 # 25 GB allocation for a40 GPU\n",
    ")\n",
    "\n",
    "tf.config.set_logical_device_configuration(\n",
    "    gpus[0], # select GPU_0, i.e., Nvidia A40\n",
    "    [log_dev_conf_a40] # apply 25GB config\n",
    ")\n",
    "\n",
    "# tf.config.set_visible_devices(gpus[1], 'GPU') # use RTX3060 only\n",
    "\n",
    "# log_dev_conf_rtx3060 = tf.config.LogicalDeviceConfiguration(\n",
    "#     memory_limit=12*1024 # 11 GB allocation for rtx3060 GPU\n",
    "# )\n",
    "\n",
    "# tf.config.set_logical_device_configuration(\n",
    "#     gpus[1], # select GPU_1, i.e., Nvidia rtx3060\n",
    "#     [log_dev_conf_rtx3060] # apply 11GB config\n",
    "# )\n",
    "\n",
    "# MultiGPU setup\n",
    "# Create a MirroredStrategy.\n",
    "# strategy = None\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from pqdm.threads import pqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (660884058.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers import AutoTokenizer, TFT5ForConditionalGeneration,\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration,\n",
    "\n",
    "# model_id = \"google-t5/t5-base\"\n",
    "model_id = 'google/flan-t5-base'\n",
    "\n",
    "# with strategy.scope():\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"models/v2\")\n",
    "# model = TFT5ForConditionalGeneration.from_pretrained(\"models/v4\")\n",
    "# model = TFT5ForConditionalGeneration.from_pretrained(\"ckpts/v4/ckpt-0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path) as input_file:\n",
    "        lines = list(map(json.loads, input_file))\n",
    "\n",
    "    return lines\n",
    "\n",
    "def load_data(root_path):\n",
    "    files = os.listdir(root_path)\n",
    "    dataset= {}\n",
    "\n",
    "    for filename in files:\n",
    "        filepath = root_path + f'/{filename}'\n",
    "\n",
    "        dataset[filename] = load_jsonl(filepath)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data('data/L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['llama3.1', 'gemma2:2b', 'gemma2']\n",
    "\n",
    "test_from = 'attrebute_val'\n",
    "train_from = 'attrebute_train'\n",
    "target_from = 'attrebute_test'\n",
    "\n",
    "train_inputs = train_from + '.data'\n",
    "train_labels = train_from + '.solution'\n",
    "\n",
    "test_inputs = test_from + '.data'\n",
    "test_labels = test_from + '.solution'\n",
    "\n",
    "target_inputs = target_from + '.data'\n",
    "\n",
    "test_inputs = dataset[test_inputs]\n",
    "test_labels = dataset[test_labels]\n",
    "train_inputs = dataset[train_inputs]\n",
    "train_labels = dataset[train_labels]\n",
    "target_inputs = dataset[target_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=250\n",
    "prompt = {\n",
    "    \"label\": \"The product belongs to these categories:\\nBrand: {details_Brand}</s>Level 0: {L0_category}</s>Level 1: {L1_category}</s>Level 2: {L2_category}</s>Level 3: {L3_category}</s>Level 4: {L4_category}</s>\",\n",
    "    # \"label\": \"The product belongs to these categories:\\nBrand: {details_Brand}\\nLevel 0: {L0_category}\\nLevel 1: {L1_category}\\nLevel 2: {L2_category}\\nLevel 3: {L3_category}\\nLevel 4: {L4_category}\",\n",
    "    \"input\": \"Categories the product into 5 levels of categories and identify the brand:\\nTitle: {title}\\nStore:{store}\\nManufacturer:{details_Manufacturer}\"\n",
    "}\n",
    "\n",
    "def make_prompt(data):\n",
    "    if 'title' in data:\n",
    "        input_type = 'input'\n",
    "    else:\n",
    "        input_type = 'label'\n",
    "\n",
    "    return prompt[input_type].format(**data)\n",
    "\n",
    "def batch_make_prompt(data):\n",
    "    return [make_prompt(item) for item in data]\n",
    "# def tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_prompts = pqdm(train_inputs, make_prompt, n_jobs=5)\n",
    "train_label_prompts = pqdm(train_labels, make_prompt, n_jobs=5)\n",
    "test_input_prompts = pqdm(test_inputs, make_prompt, n_jobs=5)\n",
    "test_label_prompts = pqdm(test_labels, make_prompt, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(inputs, labels, return_output=False):\n",
    "    inputs = [item.decode() for item in inputs]\n",
    "    labels = [item.decode() for item in labels]\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "    target_encoding = tokenizer(\n",
    "        labels,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    labels = target_encoding.input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    preds = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    if not return_output:\n",
    "        return preds.loss\n",
    "    \n",
    "    return preds, preds.loss\n",
    "\n",
    "def predict(inputs):\n",
    "    \n",
    "\n",
    "    encoding = tokenizer.batch_encode_plus(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "    outputs = model.generate(input_ids, max_new_tokens=SEQ_LEN)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_input_prompts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((\u001b[43mtrain_input_prompts\u001b[49m, train_label_prompts))\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\n\u001b[1;32m      3\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((test_input_prompts, test_label_prompts))\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_input_prompts' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 25\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_input_prompts, train_label_prompts)).shuffle(1000).batch(BATCH_SIZE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_input_prompts, test_label_prompts)).shuffle(1000).batch(BATCH_SIZE*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_input_prompts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unified_input_prompts \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_input_prompts\u001b[49m\u001b[38;5;241m.\u001b[39mextend(test_input_prompts)\n\u001b[1;32m      2\u001b[0m unified_label_prompts \u001b[38;5;241m=\u001b[39m train_label_prompts\u001b[38;5;241m.\u001b[39mextend(test_label_prompts)\n\u001b[1;32m      3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((train_input_prompts, train_label_prompts))\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_input_prompts' is not defined"
     ]
    }
   ],
   "source": [
    "unified_input_prompts = train_input_prompts.extend(test_input_prompts)\n",
    "unified_label_prompts = train_label_prompts.extend(test_label_prompts)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_input_prompts, train_label_prompts)).shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=4\n",
    "\n",
    "per_epoch_loss=[]\n",
    "\n",
    "# with strategy.scope():\n",
    "for e in range(EPOCHS):\n",
    "    dataset_iter = train_ds.as_numpy_iterator()\n",
    "\n",
    "    progbar = Progbar(len(train_ds), stateful_metrics=['train_loss'])\n",
    "    loss_metric = Mean(\"train_loss\")\n",
    "\n",
    "    for i, batch in enumerate(dataset_iter):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = train_model(inputs, labels)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        loss_metric.update_state(loss)\n",
    "        values = [('train_loss', loss_metric.result())]\n",
    "\n",
    "        progbar.update(i+1, values=values)\n",
    "\n",
    "    model.save_pretrained(f'./ckpts/v5/ckpt-{e}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./models/v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def get_metrics(y_true, y_preds):\n",
    "    return (\n",
    "        accuracy_score(y_true, y_preds),\n",
    "        precision_score(y_true, y_preds, average='macro', zero_division=0),\n",
    "        recall_score(y_true, y_preds, average='macro', zero_division=0),\n",
    "        f1_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "    )\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_categories(text):\n",
    "    key_map = {\n",
    "        'Brand': 'details_Brand',\n",
    "        'Level 0': 'L0_category',\n",
    "        'Level 1': 'L1_category',\n",
    "        'Level 2': 'L2_category',\n",
    "        'Level 3': 'L3_category',\n",
    "        'Level 4': 'L4_category'\n",
    "    }\n",
    "    \n",
    "    # Regex patterns to match each key\n",
    "    patterns = {\n",
    "        'Brand': r'Brand:\\s*(.+?)(?=\\s+Level|\\s*<\\/s>)',\n",
    "        'Level 0': r'Level 0:\\s*(.+?)(?=\\s+Level|\\s*<\\/s>)',\n",
    "        'Level 1': r'Level 1:\\s*(.+?)(?=\\s+Level|\\s*<\\/s>)',\n",
    "        'Level 2': r'Level 2:\\s*(.+?)(?=\\s+Level|\\s*<\\/s>)',\n",
    "        'Level 3': r'Level 3:\\s*(.+?)(?=\\s+Level|\\s*<\\/s>)',\n",
    "        'Level 4': r'Level 4:\\s*(.+?)(?=\\s+Level|\\s*<\\/s>)'\n",
    "    }\n",
    "    \n",
    "    # Extracting data using the patterns\n",
    "    extracted_data = {v: 'na' for v in key_map.values()}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            extracted_data[key_map[key]] = match.group(1).strip()\n",
    "    \n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_iter = test_ds.as_numpy_iterator()\n",
    "\n",
    "# progbar = Progbar(len(test_ds), stateful_metrics=['val_loss'])\n",
    "# loss_metric = Mean(\"val_loss\")\n",
    "\n",
    "# for i, batch in enumerate(dataset_iter):\n",
    "#     inputs, labels = batch\n",
    "\n",
    "#     loss = train_model(inputs, labels)\n",
    "\n",
    "#     loss_metric.update_state(loss)\n",
    "#     values = [('val_loss', loss_metric.result())]\n",
    "\n",
    "#     progbar.update(i+1, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_iter = test_ds.as_numpy_iterator()\n",
    "\n",
    "# progbar = Progbar(len(test_ds), stateful_metrics=['val_loss'])\n",
    "# acc_metric = Mean(\"val_accuracy\")\n",
    "\n",
    "# for i, batch in enumerate(dataset_iter):\n",
    "#     inputs, labels = batch\n",
    "#     labels = list(map(extract_categories, [item.decode() + '</s>' for item in labels]))\n",
    "\n",
    "#     preds = predict([item.decode() for item in inputs])\n",
    "#     preds = tokenizer.batch_decode(preds)\n",
    "#     preds = list(map(extract_categories, preds))\n",
    "\n",
    "#     labels = [list(item.values()) for item in labels]\n",
    "#     preds = [list(item.values()) for item in preds]\n",
    "\n",
    "#     labels = np.array(labels)\n",
    "#     preds = np.array(preds)\n",
    "\n",
    "#     TP = np.sum(labels == preds)\n",
    "#     FP = np.sum(labels != preds)\n",
    "\n",
    "#     accuracy = np.sum(np.all(labels == preds, axis=1))/len(labels)\n",
    "\n",
    "#     acc_metric.update_state(accuracy)\n",
    "#     values = [('val_accuracy', acc_metric.result())]\n",
    "\n",
    "#     progbar.update(i+1, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prompts = pqdm(target_inputs, make_prompt, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer(train_input_prompts[0]).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_data(item):\n",
    "    item = item.numpy().decode('utf-8')\n",
    "    encoding = tokenizer.encode(\n",
    "        item,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    return encoding[0]\n",
    "\n",
    "def batch_tokenize(batch):\n",
    "    encoding = tokenizer.batch_encode_plus(\n",
    "        batch,\n",
    "        padding=\"max_length\",\n",
    "        max_length=SEQ_LEN,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    return encoding.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_list(lst, n):\n",
    "    # Split the list into chunks of n items\n",
    "    chunks = [lst[i:i + n] for i in range(0, len(lst), n)]\n",
    "    return chunks\n",
    "\n",
    "def add_prefix(text, prefix):\n",
    "    return text + prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = chunk_list(target_prompts, n=512)\n",
    "batches = pqdm(batches, batch_tokenize, n_jobs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batches[0]\n",
    "prefix = ['The product belongs to these categories:\\nBrand:'] * input_ids.shape[0]\n",
    "prefix = tokenizer.batch_encode_plus(prefix, return_tensors='np', add_special_tokens=False).input_ids\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    decoder_input_ids=prefix,\n",
    "    max_new_tokens=10, \n",
    "    num_beams=1,\n",
    "    early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "prefix = ['The product belongs to these categories:\\nBrand:'] * input_ids.shape[0]\n",
    "prefix = tokenizer.batch_encode_plus(prefix, return_tensors='np', add_special_tokens=False).input_ids\n",
    "\n",
    "for input_ids in tqdm(batches):\n",
    "    outputs = model.generate(\n",
    "        input_ids, \n",
    "        decoder_input_ids=prefix,\n",
    "        max_new_tokens=SEQ_LEN, \n",
    "        num_beams=1,           # Setting num_beams=1 ensures greedy decoding\n",
    "        early_stopping=True)\n",
    "\n",
    "    answers.extend(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import regex as re\n",
    "# word=r'.'\n",
    "# pattern = rf\"(Brand:\\s?{word}+)? (Level 0:\\s?{word}+)? (Level 1:\\s?{word}+)? (Level 2:\\s?{word}+)? (Level 3:\\s?{word}+)? (Level 4:\\s?{word}+)?\"\n",
    "\n",
    "# def extract_categories(output):\n",
    "\n",
    "#     brand, l0, l1, l2, l3, l4 = re.findall(pattern, output)[0]\n",
    "#     return {\n",
    "#         'details_Brand': brand,\n",
    "#         'L0_category': l0,\n",
    "#         'L1_category': l1,\n",
    "#         'L2_category': l2,\n",
    "#         'L3_category': l3,\n",
    "#         'L4_category': l4\n",
    "#     }\n",
    "# print(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_outputs = []\n",
    "for i, item in enumerate(tqdm(answers)):\n",
    "    details = {'indoml_id': i}\n",
    "    details.update(extract_categories(item))\n",
    "\n",
    "    final_outputs.append(json.dumps(details) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output/L4/'\n",
    "\n",
    "with open(output_path + 'attribute_test_topjourney4.predict', 'w') as output_file:\n",
    "    output_file.writelines(final_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
